#!/usr/bin/env python3
"""
ì…ì°° ë©”íƒ€ ì¸ì§€ ë¶„ì„ - ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

AIê°€ ë¨¼ì € ìƒê°í•˜ê³  ê²€ì¦í•˜ê³  ë°œê²¬í•˜ëŠ” ë‹¨ê³„
- ìš”ì¸ë³„ í†µê³„ ê²€ì¦
- ë‹¤ì¤‘ ì „ëµ ìƒì„±
- ëŠ¥ë™ì  íŒ¨í„´ ë°œê²¬
- ì‹ ë¢°ë„ í‰ê°€
"""

import argparse
import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

# ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from modules.factor_validator import validate_factors
    from modules.strategy_generator import generate_strategies
    from modules.insight_finder import find_insights
    from modules.data_utils import filter_valid_range
    MODULE_AVAILABLE = True
except ImportError as e:
    MODULE_AVAILABLE = False
    print(f"âš ï¸ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")


class MetaCognitionAnalyzer:
    """ë©”íƒ€ ì¸ì§€ ë¶„ì„ê¸°"""

    def __init__(self,
                 data_file: str,
                 basic_result_file: Optional[str] = None,
                 advanced_result_file: Optional[str] = None,
                 context: Optional[Dict] = None):
        """
        ì´ˆê¸°í™”

        Args:
            data_file: ì „ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼
            basic_result_file: ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ JSON
            advanced_result_file: ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ JSON
            context: í˜„ì¬ ìƒí™© (ë°œì£¼ì²˜, ì›”, ê¸ˆì•¡ ë“±)
        """
        self.data_file = data_file
        self.basic_result_file = basic_result_file
        self.advanced_result_file = advanced_result_file
        self.context = context or {}

        self.df = None
        self.basic_result = None
        self.advanced_result = None
        self.meta_result = {
            "ë©”íƒ€ì •ë³´": {
                "ë¶„ì„ì‹œê°": datetime.now().isoformat(),
                "ë°ì´í„°íŒŒì¼": data_file,
                "ì»¨í…ìŠ¤íŠ¸": self.context
            }
        }

    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        print(f"\n{'='*80}")
        print("ë©”íƒ€ ì¸ì§€ ë¶„ì„ ì‹œì‘")
        print(f"{'='*80}")
        print(f"\n[ë°ì´í„° ë¡œë“œ] {self.data_file}")

        self.df = pd.read_excel(self.data_file)
        self.df = filter_valid_range(self.df)  # âœ… í•„í„°ë§ ì¶”ê°€
        print(f"  âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.df):,}ê±´")

        # ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        if self.basic_result_file and Path(self.basic_result_file).exists():
            with open(self.basic_result_file, 'r', encoding='utf-8') as f:
                self.basic_result = json.load(f)
            print(f"  âœ… ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ë¡œë“œ")

        # ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        if self.advanced_result_file and Path(self.advanced_result_file).exists():
            with open(self.advanced_result_file, 'r', encoding='utf-8') as f:
                self.advanced_result = json.load(f)
            print(f"  âœ… ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ ë¡œë“œ")

    def run_factor_validation(self):
        """ìš”ì¸ë³„ í†µê³„ ê²€ì¦"""
        print(f"\n{'='*80}")
        print("Step 1: ìš”ì¸ë³„ í†µê³„ ê²€ì¦")
        print(f"{'='*80}")

        try:
            validated_factors = validate_factors(self.df)
            self.meta_result["ê²€ì¦ëœ_ì˜í–¥ìš”ì¸"] = validated_factors

            # ìœ ì˜ë¯¸í•œ ìš”ì¸ ê°œìˆ˜
            significant_count = sum(1 for f in validated_factors if f.get('ìœ ì˜ë¯¸', False))
            print(f"\n  âœ… ê²€ì¦ ì™„ë£Œ: ì´ {len(validated_factors)}ê°œ ìš”ì¸, {significant_count}ê°œ ìœ ì˜ë¯¸")

            return validated_factors

        except Exception as e:
            print(f"  âŒ ì˜¤ë¥˜: {e}")
            return []

    def run_strategy_generation(self, validated_factors):
        """ë‹¤ì¤‘ ì „ëµ ìƒì„±"""
        print(f"\n{'='*80}")
        print("Step 2: ë‹¤ì¤‘ ì „ëµ ìƒì„±")
        print(f"{'='*80}")

        # ê¸°ì´ˆê¸ˆì•¡, ë°œì£¼ì²˜íˆ¬ì°°ë¥  ì¶”ì¶œ
        base_amount = self.context.get('ê¸°ì´ˆê¸ˆì•¡', self.df['ê¸°ì´ˆê¸ˆì•¡'].median())
        agency_rate = self.context.get('ë°œì£¼ì²˜íˆ¬ì°°ë¥ ', 87.745)

        try:
            strategies = generate_strategies(
                df=self.df,
                base_amount=base_amount,
                agency_rate=agency_rate,
                basic_result=self.basic_result,
                validated_factors=validated_factors,
                context=self.context
            )
            self.meta_result["ìƒì„±ëœ_ì „ëµ"] = strategies

            print(f"\n  âœ… ì „ëµ ìƒì„± ì™„ë£Œ: {len(strategies)}ê°œ")

            return strategies

        except Exception as e:
            print(f"  âŒ ì˜¤ë¥˜: {e}")
            return []

    def run_insight_discovery(self):
        """ëŠ¥ë™ì  íŒ¨í„´ ë°œê²¬"""
        print(f"\n{'='*80}")
        print("Step 3: ëŠ¥ë™ì  íŒ¨í„´ ë°œê²¬")
        print(f"{'='*80}")

        try:
            insights = find_insights(self.df)
            self.meta_result["ëŠ¥ë™ì _ë°œê²¬"] = insights

            print(f"\n  âœ… íŒ¨í„´ ë°œê²¬ ì™„ë£Œ: {len(insights)}ê°œ")

            return insights

        except Exception as e:
            print(f"  âŒ ì˜¤ë¥˜: {e}")
            return []

    def run_confidence_assessment(self, validated_factors, strategies):
        """ì‹ ë¢°ë„ í‰ê°€"""
        print(f"\n{'='*80}")
        print("Step 4: ì‹ ë¢°ë„ í‰ê°€")
        print(f"{'='*80}")

        try:
            # 1. ë°ì´í„° ì¶©ë¶„ì„±
            winners = self.df[self.df['ìˆœìœ„'] == 1]
            data_sufficiency = min(len(winners) / 100, 1.0)  # 100ê±´ ì´ìƒì´ë©´ 1.0

            # 2. ì»¨í…ìŠ¤íŠ¸ ë§¤ì¹­
            context_match = self._calculate_context_match()

            # 3. ì‹œê°„ì  ìœ íš¨ì„±
            temporal_validity = self._calculate_temporal_validity()

            # 4. ì´ìƒì¹˜ ì—¬ë¶€
            is_outlier = self._check_outlier()

            # ì „ì²´ ì‹ ë¢°ë„ (ê°€ì¤‘ í‰ê· )
            overall_confidence = (
                data_sufficiency * 0.3 +
                context_match * 0.4 +
                temporal_validity * 0.3
            )

            # ì´ìƒì¹˜ë©´ ì‹ ë¢°ë„ ê°ì†Œ
            if is_outlier:
                overall_confidence *= 0.7

            # í‰ê°€
            if overall_confidence >= 0.7:
                assessment = "ë†’ìŒ"
                recommendation = "ê³¼ê±° íŒ¨í„´ì„ ë†’ì€ ì‹ ë¢°ë„ë¡œ ì°¸ê³  ê°€ëŠ¥"
            elif overall_confidence >= 0.5:
                assessment = "ë³´í†µ"
                recommendation = "ê³¼ê±° íŒ¨í„´ ì°¸ê³  ê°€ëŠ¥í•˜ë‚˜, í˜„ì¬ ìƒí™© íŠ¹ì„± ê³ ë ¤ í•„ìš”"
            else:
                assessment = "ë‚®ìŒ"
                recommendation = "ê³¼ê±° ë°ì´í„°ì™€ í˜„ì¬ ìƒí™©ì´ ë‹¤ë¦„, ì‹ ì¤‘í•œ íŒë‹¨ í•„ìš”"

            confidence_result = {
                "ì „ì²´_ì‹ ë¢°ë„": round(overall_confidence, 2),
                "í‰ê°€": assessment,
                "ê·¼ê±°": {
                    "ë°ì´í„°_ì¶©ë¶„ì„±": round(data_sufficiency, 2),
                    "ì»¨í…ìŠ¤íŠ¸_ë§¤ì¹­": round(context_match, 2),
                    "ì‹œê°„ì _ìœ íš¨ì„±": round(temporal_validity, 2),
                    "ì´ìƒì¹˜_ì—¬ë¶€": is_outlier
                },
                "ê¶Œì¥ì‚¬í•­": recommendation
            }

            self.meta_result["ì‹ ë¢°ë„_í‰ê°€"] = confidence_result

            print(f"  âœ… ì‹ ë¢°ë„ í‰ê°€: {overall_confidence:.2f} ({assessment})")
            print(f"     - ë°ì´í„° ì¶©ë¶„ì„±: {data_sufficiency:.2f}")
            print(f"     - ì»¨í…ìŠ¤íŠ¸ ë§¤ì¹­: {context_match:.2f}")
            print(f"     - ì‹œê°„ì  ìœ íš¨ì„±: {temporal_validity:.2f}")
            print(f"     - ì´ìƒì¹˜ ì—¬ë¶€: {is_outlier}")

            # ìµœì¢… ì¶”ì²œ
            self._generate_final_recommendation(strategies, confidence_result, validated_factors)

            return confidence_result

        except Exception as e:
            print(f"  âŒ ì˜¤ë¥˜: {e}")
            return {}

    def _calculate_context_match(self) -> float:
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        if not self.context:
            return 0.5  # ì»¨í…ìŠ¤íŠ¸ ì—†ìœ¼ë©´ ì¤‘ê°„ê°’

        match_score = 0.0
        factors = 0

        # ë°œì£¼ì²˜ ë§¤ì¹­
        if 'ë°œì£¼ì²˜' in self.context and 'ë°œì£¼ì²˜' in self.df.columns:
            current_agency = self.context['ë°œì£¼ì²˜']
            if current_agency in self.df['ë°œì£¼ì²˜'].values:
                agency_count = len(self.df[self.df['ë°œì£¼ì²˜'] == current_agency])
                match_score += min(agency_count / 50, 1.0)  # 50ê±´ ì´ìƒì´ë©´ 1.0
            factors += 1

        # ê¸ˆì•¡ ë§¤ì¹­ (í‰ê· ê³¼ì˜ ì°¨ì´)
        if 'ê¸°ì´ˆê¸ˆì•¡' in self.context:
            current_amount = self.context['ê¸°ì´ˆê¸ˆì•¡']
            avg_amount = self.df['ê¸°ì´ˆê¸ˆì•¡'].mean()
            std_amount = self.df['ê¸°ì´ˆê¸ˆì•¡'].std()

            # Z-score ê³„ì‚°
            z_score = abs(current_amount - avg_amount) / std_amount if std_amount > 0 else 0
            # Z-scoreê°€ í´ìˆ˜ë¡ ë§¤ì¹­ ë‚®ìŒ
            amount_match = max(1.0 - z_score / 3, 0.0)  # 3Ïƒ ì´ìƒì´ë©´ 0
            match_score += amount_match
            factors += 1

        # ì›” ë§¤ì¹­
        if 'ì›”' in self.context and 'ì›”' in self.df.columns:
            current_month = self.context['ì›”']
            if current_month in self.df['ì›”'].values:
                month_count = len(self.df[self.df['ì›”'] == current_month])
                match_score += min(month_count / 30, 1.0)  # 30ê±´ ì´ìƒì´ë©´ 1.0
            factors += 1

        return match_score / factors if factors > 0 else 0.5

    def _calculate_temporal_validity(self) -> float:
        """ì‹œê°„ì  ìœ íš¨ì„± ê³„ì‚°"""
        if 'ì…ì°°ì¼ì‹œ' not in self.df.columns:
            return 0.5

        try:
            self.df['ì…ì°°ì¼ì‹œ_parsed'] = pd.to_datetime(self.df['ì…ì°°ì¼ì‹œ'], errors='coerce')
            valid_df = self.df.dropna(subset=['ì…ì°°ì¼ì‹œ_parsed'])

            if len(valid_df) == 0:
                return 0.5

            # ìµœê·¼ 6ê°œì›” ë°ì´í„° ë¹„ì¤‘
            six_months_ago = datetime.now() - pd.Timedelta(days=180)
            recent_count = len(valid_df[valid_df['ì…ì°°ì¼ì‹œ_parsed'] >= six_months_ago])
            total_count = len(valid_df)

            return recent_count / total_count

        except:
            return 0.5

    def _check_outlier(self) -> bool:
        """í˜„ì¬ ìƒí™©ì´ ì´ìƒì¹˜ì¸ì§€ í™•ì¸"""
        if 'ê¸°ì´ˆê¸ˆì•¡' not in self.context:
            return False

        current_amount = self.context['ê¸°ì´ˆê¸ˆì•¡']
        mean_amount = self.df['ê¸°ì´ˆê¸ˆì•¡'].mean()
        std_amount = self.df['ê¸°ì´ˆê¸ˆì•¡'].std()

        if std_amount == 0:
            return False

        z_score = abs(current_amount - mean_amount) / std_amount

        # Z-score > 3ì´ë©´ ì´ìƒì¹˜
        return z_score > 3

    def _generate_final_recommendation(self, strategies, confidence, validated_factors):
        """ìµœì¢… ì¶”ì²œ ìƒì„±"""
        if not strategies:
            return

        # ì‹ ë¢°ë„ì— ë”°ë¼ ì „ëµ ì„ íƒ
        if confidence['ì „ì²´_ì‹ ë¢°ë„'] >= 0.7:
            # ë†’ì€ ì‹ ë¢°ë„: ë§ì¶¤ ì „ëµ ìš°ì„ , ì—†ìœ¼ë©´ ê· í˜•
            recommended = next((s for s in strategies if s['ì „ëµëª…'] == 'ìƒí™©ë§ì¶¤'), None)
            if not recommended:
                recommended = next((s for s in strategies if s['ì „ëµëª…'] == 'ê· í˜•'), strategies[0])
            reason = "ë†’ì€ ì‹ ë¢°ë„, ë§ì¶¤ ì „ëµ ì¶”ì²œ"

        elif confidence['ì „ì²´_ì‹ ë¢°ë„'] >= 0.5:
            # ì¤‘ê°„ ì‹ ë¢°ë„: ê· í˜• ì „ëµ
            recommended = next((s for s in strategies if s['ì „ëµëª…'] == 'ê· í˜•'), strategies[0])
            reason = "ì¤‘ê°„ ì‹ ë¢°ë„, ê· í˜• ì „ëµ ì¶”ì²œ"

        else:
            # ë‚®ì€ ì‹ ë¢°ë„: ë³´ìˆ˜ì  ì „ëµ
            recommended = next((s for s in strategies if s['ì „ëµëª…'] == 'ë³´ìˆ˜ì '), strategies[0])
            reason = "ë‚®ì€ ì‹ ë¢°ë„, ë³´ìˆ˜ì  ì „ëµ ì¶”ì²œ"

        # ìœ ì˜ë¯¸í•œ ìš”ì¸ ë°˜ì˜ ì—¬ë¶€
        significant_factors = [f['ìš”ì¸'] for f in validated_factors if f.get('ìœ ì˜ë¯¸', False)]
        if significant_factors:
            reason += f" (ë°˜ì˜ ìš”ì¸: {', '.join(significant_factors)})"

        self.meta_result["ìµœì¢…_ì¶”ì²œ"] = {
            "ì „ëµ": recommended['ì „ëµëª…'],
            "ì…ì°°ë¥ ": recommended['ì…ì°°ë¥ '],
            "ì…ì°°ê¸ˆì•¡": recommended['ì…ì°°ê¸ˆì•¡'],
            "ì‹ ë¢°ë„": confidence['ì „ì²´_ì‹ ë¢°ë„'],
            "ì´ìœ ": reason
        }

    def _convert_to_python_types(self, obj):
        """numpy íƒ€ì…ì„ Python ë„¤ì´í‹°ë¸Œ íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
        if isinstance(obj, dict):
            return {key: self._convert_to_python_types(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_to_python_types(item) for item in obj]
        elif isinstance(obj, (np.integer, np.int64, np.int32)):
            return int(obj)
        elif isinstance(obj, (np.floating, np.float64, np.float32)):
            return float(obj)
        elif isinstance(obj, np.bool_):
            return bool(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        else:
            return obj

    def save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        # íˆ¬ì°°ë¥  ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ)
        filename = Path(self.data_file).stem
        if '_' in filename:
            rate_part = filename.split('_')[1]  # "87"
            rate_int = int(rate_part.replace('%', ''))
        else:
            rate_int = 87745

        output_file = f"/mnt/a/25/dataë¶„ì„/meta_analysis_{rate_int}.json"
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # numpy íƒ€ì… ë³€í™˜
        converted_result = self._convert_to_python_types(self.meta_result)

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(converted_result, f, ensure_ascii=False, indent=2)

        print(f"\n{'='*80}")
        print("ë©”íƒ€ ë¶„ì„ ì™„ë£Œ!")
        print(f"{'='*80}")
        print(f"ê²°ê³¼ íŒŒì¼: {output_file}")

        # ìš”ì•½ ì¶œë ¥
        if "ìµœì¢…_ì¶”ì²œ" in self.meta_result:
            rec = self.meta_result["ìµœì¢…_ì¶”ì²œ"]
            print(f"\nğŸ“Š ìµœì¢… ì¶”ì²œ:")
            print(f"   ì „ëµ: {rec['ì „ëµ']}")
            print(f"   ì…ì°°ë¥ : {rec['ì…ì°°ë¥ ']}%")
            print(f"   ì…ì°°ê¸ˆì•¡: {rec['ì…ì°°ê¸ˆì•¡']:,}ì›")
            print(f"   ì‹ ë¢°ë„: {rec['ì‹ ë¢°ë„']}")
            print(f"   ì´ìœ : {rec['ì´ìœ ']}")

        return output_file

    def run_full_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        # ë°ì´í„° ë¡œë“œ
        self.load_data()

        # Step 1: ìš”ì¸ ê²€ì¦
        validated_factors = self.run_factor_validation()

        # Step 2: ì „ëµ ìƒì„±
        strategies = self.run_strategy_generation(validated_factors)

        # Step 3: ì¸ì‚¬ì´íŠ¸ ë°œê²¬
        insights = self.run_insight_discovery()

        # Step 4: ì‹ ë¢°ë„ í‰ê°€
        confidence = self.run_confidence_assessment(validated_factors, strategies)

        # ê²°ê³¼ ì €ì¥
        output_file = self.save_results()

        return self.meta_result


def main():
    """CLI ì§„ì…ì """
    parser = argparse.ArgumentParser(
        description='ì…ì°° ë©”íƒ€ ì¸ì§€ ë¶„ì„ - AIê°€ ë¨¼ì € ìƒê°í•˜ê³  ê²€ì¦í•˜ê³  ë°œê²¬'
    )
    parser.add_argument(
        '--data-file',
        type=str,
        required=True,
        help='ì „ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼ ê²½ë¡œ'
    )
    parser.add_argument(
        '--basic-result',
        type=str,
        help='ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼'
    )
    parser.add_argument(
        '--advanced-result',
        type=str,
        help='ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼'
    )
    parser.add_argument(
        '--context',
        type=str,
        help='í˜„ì¬ ìƒí™© (JSON ë¬¸ìì—´, ì˜ˆ: \'{"ë°œì£¼ì²˜": "êµ­ê°€ìœ ì‚°ì²­", "ì›”": 12}\')'
    )

    args = parser.parse_args()

    # ì»¨í…ìŠ¤íŠ¸ íŒŒì‹±
    context = None
    if args.context:
        try:
            context = json.loads(args.context)
        except:
            print(f"âš ï¸ ì»¨í…ìŠ¤íŠ¸ íŒŒì‹± ì‹¤íŒ¨: {args.context}")

    # ë¶„ì„ê¸° ìƒì„± ë° ì‹¤í–‰
    analyzer = MetaCognitionAnalyzer(
        data_file=args.data_file,
        basic_result_file=args.basic_result,
        advanced_result_file=args.advanced_result,
        context=context
    )

    analyzer.run_full_analysis()


if __name__ == '__main__':
    main()
